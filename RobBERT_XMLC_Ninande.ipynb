{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca1575e",
   "metadata": {},
   "source": [
    "# RobBERT-XMLC model for Explicit and Implicit skill-extraction\n",
    "\n",
    "This code is created as part of the Master Thesis of Ninande Vermeer: \"Using RobBERT for Implicit and Explicit Skill-Extraction from Dutch Job Descriptions\". It can be used to conduct the experiments of the project. The Sample and RO sample data cannot be shared. However, the dataset of Bhola et al. can be found on their official Github repository: https://github.com/WING-NUS/JD2Skills-BERT-XMLC. \n",
    "\n",
    "In order to conduct the different experiments, change the \"change this\" variables in the Settings section.\n",
    "\n",
    "## Packages and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591814a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and visualization\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import io\n",
    "\n",
    "# Math\n",
    "import numpy as np\n",
    "\n",
    "# Time and Logging\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# BERT model (simpletransformers will install all required packages)\n",
    "!pip install --upgrade torch\n",
    "import torch\n",
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ADJUSTED MODULES OF SIMPLETRANSFORMERS AND USED PACKAGES\n",
    "'''\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    RobertaModel\n",
    ")\n",
    "from transformers.models.bert.modeling_bert import BertPreTrainedModel\n",
    "\n",
    "from transformers.models.roberta.modeling_roberta import (\n",
    "    ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST,\n",
    "    RobertaClassificationHead,\n",
    "    RobertaConfig,\n",
    "    RobertaModel,\n",
    ")\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AlbertConfig,\n",
    "    AlbertTokenizer,\n",
    "    BertConfig,\n",
    "    BertTokenizer,\n",
    "    BertweetTokenizer,\n",
    "    BigBirdConfig,\n",
    "    BigBirdTokenizer,\n",
    "    CamembertConfig,\n",
    "    CamembertTokenizer,\n",
    "    DistilBertConfig,\n",
    "    DistilBertTokenizer,\n",
    "    ElectraConfig,\n",
    "    ElectraTokenizer,\n",
    "    FlaubertConfig,\n",
    "    FlaubertTokenizer,\n",
    "    LongformerConfig,\n",
    "    LongformerTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaTokenizer,\n",
    "    XLMConfig,\n",
    "    XLMRobertaConfig,\n",
    "    XLMRobertaTokenizer,\n",
    "    XLMTokenizer,\n",
    "    XLNetConfig,\n",
    "    XLNetTokenizer,\n",
    ")\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "from simpletransformers.config.global_args import global_args\n",
    "from simpletransformers.config.model_args import MultiLabelClassificationArgs\n",
    "from simpletransformers.config.utils import sweep_config_to_sweep_values\n",
    "from simpletransformers.custom_models.models import (\n",
    "    AlbertForMultiLabelSequenceClassification,\n",
    "    BertForMultiLabelSequenceClassification,\n",
    "    BertweetForMultiLabelSequenceClassification,\n",
    "    BigBirdForMultiLabelSequenceClassification,\n",
    "    CamembertForMultiLabelSequenceClassification,\n",
    "    DistilBertForMultiLabelSequenceClassification,\n",
    "    ElectraForMultiLabelSequenceClassification,\n",
    "    FlaubertForMultiLabelSequenceClassification,\n",
    "    LongformerForMultiLabelSequenceClassification,\n",
    "    RobertaForMultiLabelSequenceClassification,\n",
    "    XLMForMultiLabelSequenceClassification,\n",
    "    XLMRobertaForMultiLabelSequenceClassification,\n",
    "    XLNetForMultiLabelSequenceClassification,\n",
    ")\n",
    "\n",
    "# 2-LAYERED BERT-XMLC\n",
    "class BertForMultiLabelSequenceClassificationXMLC(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Two-layered Bert model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(BertForMultiLabelSequenceClassificationXMLC, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "        \n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.classifier_1 = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.classifier_1(logits)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs  # (loss), logits, (hidden_states), (attentions)\n",
    "    \n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "\n",
    "# 2-LAYERED ROBBERT-XMLC\n",
    "\n",
    "class RobertaForMultiLabelSequenceClassificationXMLC(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Two-layered Roberta model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassificationXMLC, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.classifier_1 = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            labels=None,\n",
    "        ):\n",
    "\n",
    "        outputs = self.roberta(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        logits = self.relu(logits)\n",
    "        logits = self.classifier_1(logits)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "            \n",
    "# 1-LAYERED ROBBERT-XMLC\n",
    "\n",
    "class RobertaForMultiLabelSequenceClassificationXMLC1(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Single-layered Roberta model adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassificationXMLC1, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            labels=None,\n",
    "        ):\n",
    "\n",
    "        outputs = self.roberta(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "            \n",
    "# 1-LAYERED ROBBERT-XMLC without dropout\n",
    "\n",
    "class RobertaForMultiLabelSequenceClassificationXMLCBasic(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Single-layered Roberta model without dropout layer, adapted for multi-label sequence classification\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = RobertaConfig\n",
    "    pretrained_model_archive_map = ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST\n",
    "    base_model_prefix = \"roberta\"\n",
    "\n",
    "    def __init__(self, config, pos_weight=None):\n",
    "        super(RobertaForMultiLabelSequenceClassificationXMLCBasic, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            position_ids=None,\n",
    "            head_mask=None,\n",
    "            labels=None,\n",
    "        ):\n",
    "\n",
    "        outputs = self.roberta(input_ids, token_type_ids=token_type_ids,attention_mask=attention_mask, head_mask=head_mask)\n",
    "        pooled_output = outputs[1]\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss(pos_weight=self.pos_weight)\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(\n",
    "                logits.view(-1, self.num_labels), labels.view(-1, self.num_labels)\n",
    "            )\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def unfreeze(self,start_layer,end_layer):\n",
    "        def children(m):\n",
    "            return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "        def set_trainable_attr(m, b):\n",
    "            m.trainable = b\n",
    "            for p in m.parameters():\n",
    "                p.requires_grad = b\n",
    "        def apply_leaf(m, f):\n",
    "            c = children(m)\n",
    "            if isinstance(m, nn.Module):\n",
    "                f(m)\n",
    "            if len(c) > 0:\n",
    "                for l in c:\n",
    "                    apply_leaf(l, f)\n",
    "        def set_trainable(l, b):\n",
    "            apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "\n",
    "        # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "        set_trainable(self.bert, False)\n",
    "        for i in range(start_layer, end_layer+1):\n",
    "            set_trainable(self.bert.encoder.layer[i], True)\n",
    "            \n",
    "#### Modified classification model\n",
    "            \n",
    "class MultiLabelClassificationModel(ClassificationModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_type,\n",
    "        model_name,\n",
    "        num_labels=None,\n",
    "        pos_weight=None,\n",
    "        args=None,\n",
    "        use_cuda=True,\n",
    "        cuda_device=-1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        Initializes a MultiLabelClassification model.\n",
    "        Args:\n",
    "            model_type: The type of model (bert, roberta)\n",
    "            model_name: Default Transformer model name or path to a directory containing Transformer model file (pytorch_nodel.bin).\n",
    "            num_labels (optional): The number of labels or classes in the dataset.\n",
    "            pos_weight (optional): A list of length num_labels containing the weights to assign to each label for loss calculation.\n",
    "            args (optional): Default args will be used if this parameter is not provided. If provided, it should be a dict containing the args that should be changed in the default args.\n",
    "            use_cuda (optional): Use GPU if available. Setting to False will force model to use CPU only.\n",
    "            cuda_device (optional): Specific GPU that should be used. Will use the first available GPU by default.\n",
    "            **kwargs (optional): For providing proxies, force_download, resume_download, cache_dir and other options specific to the 'from_pretrained' implementation where this will be supplied.\n",
    "        \"\"\"  # noqa: ignore flake8\"\n",
    "\n",
    "        MODEL_CLASSES = {\n",
    "            \"albert\": (\n",
    "                AlbertConfig,\n",
    "                AlbertForMultiLabelSequenceClassification,\n",
    "                AlbertTokenizer,\n",
    "            ),\n",
    "            \"bert\": (\n",
    "                BertConfig,\n",
    "                BertForMultiLabelSequenceClassification,\n",
    "                BertTokenizer,\n",
    "            ),\n",
    "            \"bert_xmlc\": (\n",
    "                BertConfig,\n",
    "                BertForMultiLabelSequenceClassificationXMLC,\n",
    "                BertTokenizer,\n",
    "            ),\n",
    "            \"bertweet\": (\n",
    "                RobertaConfig,\n",
    "                BertweetForMultiLabelSequenceClassification,\n",
    "                BertweetTokenizer,\n",
    "            ),\n",
    "            \"bigbird\": (\n",
    "                BigBirdConfig,\n",
    "                BigBirdForMultiLabelSequenceClassification,\n",
    "                BigBirdTokenizer,\n",
    "            ),\n",
    "            \"camembert\": (\n",
    "                CamembertConfig,\n",
    "                CamembertForMultiLabelSequenceClassification,\n",
    "                CamembertTokenizer,\n",
    "            ),\n",
    "            \"distilbert\": (\n",
    "                DistilBertConfig,\n",
    "                DistilBertForMultiLabelSequenceClassification,\n",
    "                DistilBertTokenizer,\n",
    "            ),\n",
    "            \"electra\": (\n",
    "                ElectraConfig,\n",
    "                ElectraForMultiLabelSequenceClassification,\n",
    "                ElectraTokenizer,\n",
    "            ),\n",
    "            \"flaubert\": (\n",
    "                FlaubertConfig,\n",
    "                FlaubertForMultiLabelSequenceClassification,\n",
    "                FlaubertTokenizer,\n",
    "            ),\n",
    "            \"longformer\": (\n",
    "                LongformerConfig,\n",
    "                LongformerForMultiLabelSequenceClassification,\n",
    "                LongformerTokenizer,\n",
    "            ),\n",
    "            \"roberta\": (\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassification,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            \"roberta_xmlc\": (\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassificationXMLC,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            \"roberta_xmlc1\": (\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassificationXMLC1,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            'roberta_xmlc_basic':(\n",
    "                RobertaConfig,\n",
    "                RobertaForMultiLabelSequenceClassificationXMLCBasic,\n",
    "                RobertaTokenizer,\n",
    "            ),\n",
    "            \"xlm\": (XLMConfig, XLMForMultiLabelSequenceClassification, XLMTokenizer),\n",
    "            \"xlmroberta\": (\n",
    "                XLMRobertaConfig,\n",
    "                XLMRobertaForMultiLabelSequenceClassification,\n",
    "                XLMRobertaTokenizer,\n",
    "            ),\n",
    "            \"xlnet\": (\n",
    "                XLNetConfig,\n",
    "                XLNetForMultiLabelSequenceClassification,\n",
    "                XLNetTokenizer,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        self.args = self._load_model_args(model_name)\n",
    "\n",
    "        if isinstance(args, dict):\n",
    "            self.args.update_from_dict(args)\n",
    "        elif isinstance(args, MultiLabelClassificationArgs):\n",
    "            self.args = args\n",
    "\n",
    "        if self.args.thread_count:\n",
    "            torch.set_num_threads(self.args.thread_count)\n",
    "\n",
    "        if \"sweep_config\" in kwargs:\n",
    "            self.is_sweeping = True\n",
    "            sweep_config = kwargs.pop(\"sweep_config\")\n",
    "            sweep_values = sweep_config_to_sweep_values(sweep_config)\n",
    "            self.args.update_from_dict(sweep_values)\n",
    "        else:\n",
    "            self.is_sweeping = False\n",
    "\n",
    "        if self.args.manual_seed:\n",
    "            random.seed(self.args.manual_seed)\n",
    "            np.random.seed(self.args.manual_seed)\n",
    "            torch.manual_seed(self.args.manual_seed)\n",
    "            if self.args.n_gpu > 0:\n",
    "                torch.cuda.manual_seed_all(self.args.manual_seed)\n",
    "\n",
    "        if not use_cuda:\n",
    "            self.args.fp16 = False\n",
    "\n",
    "        config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "        if num_labels:\n",
    "            self.config = config_class.from_pretrained(\n",
    "                model_name, num_labels=num_labels, **self.args.config\n",
    "            )\n",
    "            self.num_labels = num_labels\n",
    "        else:\n",
    "            self.config = config_class.from_pretrained(model_name, **self.args.config)\n",
    "            self.num_labels = self.config.num_labels\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                if cuda_device == -1:\n",
    "                    self.device = torch.device(\"cuda\")\n",
    "                else:\n",
    "                    self.device = torch.device(f\"cuda:{cuda_device}\")\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"'use_cuda' set to True when cuda is unavailable.\"\n",
    "                    \" Make sure CUDA is available or set use_cuda=False.\"\n",
    "                )\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "\n",
    "        if not self.args.quantized_model:\n",
    "            if self.pos_weight:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    model_name,\n",
    "                    config=self.config,\n",
    "                    pos_weight=torch.Tensor(self.pos_weight).to(self.device),\n",
    "                    **kwargs,\n",
    "                )\n",
    "            else:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    model_name, config=self.config, **kwargs\n",
    "                )\n",
    "        else:\n",
    "            quantized_weights = torch.load(\n",
    "                os.path.join(model_name, \"pytorch_model.bin\")\n",
    "            )\n",
    "            if self.pos_weight:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    None,\n",
    "                    config=self.config,\n",
    "                    state_dict=quantized_weights,\n",
    "                    weight=torch.Tensor(self.pos_weight).to(self.device),\n",
    "                )\n",
    "            else:\n",
    "                self.model = model_class.from_pretrained(\n",
    "                    None, config=self.config, state_dict=quantized_weights\n",
    "                )\n",
    "\n",
    "        if self.args.dynamic_quantize:\n",
    "            self.model = torch.quantization.quantize_dynamic(\n",
    "                self.model, {torch.nn.Linear}, dtype=torch.qint8\n",
    "            )\n",
    "        if self.args.quantized_model:\n",
    "            self.model.load_state_dict(quantized_weights)\n",
    "        if self.args.dynamic_quantize:\n",
    "            self.args.quantized_model = True\n",
    "\n",
    "        self.results = {}\n",
    "\n",
    "        self.tokenizer = tokenizer_class.from_pretrained(\n",
    "            model_name, do_lower_case=self.args.do_lower_case, **kwargs\n",
    "        )\n",
    "\n",
    "        if self.args.special_tokens_list:\n",
    "            self.tokenizer.add_tokens(\n",
    "                self.args.special_tokens_list, special_tokens=True\n",
    "            )\n",
    "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "\n",
    "        self.args.model_name = model_name\n",
    "        self.args.model_type = model_type\n",
    "\n",
    "        if self.args.wandb_project and not wandb_available:\n",
    "            warnings.warn(\n",
    "                \"wandb_project specified but wandb is not available. Wandb disabled.\"\n",
    "            )\n",
    "            self.args.wandb_project = None\n",
    "\n",
    "        self.weight = None  # Not implemented for multilabel\n",
    "\n",
    "    def _load_model_args(self, input_dir):\n",
    "        args = MultiLabelClassificationArgs()\n",
    "        args.load(input_dir)\n",
    "        return args\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        train_df,\n",
    "        multi_label=True,\n",
    "        eval_df=None,\n",
    "        output_dir=None,\n",
    "        show_running_loss=True,\n",
    "        args=None,\n",
    "        verbose=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return super().train_model(\n",
    "            train_df,\n",
    "            multi_label=multi_label,\n",
    "            eval_df=eval_df,\n",
    "            output_dir=output_dir,\n",
    "            show_running_loss=show_running_loss,\n",
    "            verbose=True,\n",
    "            args=args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def eval_model(\n",
    "        self,\n",
    "        eval_df,\n",
    "        multi_label=True,\n",
    "        output_dir=None,\n",
    "        verbose=False,\n",
    "        silent=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return super().eval_model(\n",
    "            eval_df,\n",
    "            output_dir=output_dir,\n",
    "            multi_label=multi_label,\n",
    "            verbose=verbose,\n",
    "            silent=silent,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def evaluate(\n",
    "        self,\n",
    "        eval_df,\n",
    "        output_dir,\n",
    "        multi_label=True,\n",
    "        prefix=\"\",\n",
    "        verbose=True,\n",
    "        silent=False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        return super().evaluate(\n",
    "            eval_df,\n",
    "            output_dir,\n",
    "            multi_label=multi_label,\n",
    "            prefix=prefix,\n",
    "            verbose=verbose,\n",
    "            silent=silent,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def load_and_cache_examples(\n",
    "        self,\n",
    "        examples,\n",
    "        evaluate=False,\n",
    "        no_cache=False,\n",
    "        multi_label=True,\n",
    "        verbose=True,\n",
    "        silent=False,\n",
    "    ):\n",
    "        return super().load_and_cache_examples(\n",
    "            examples,\n",
    "            evaluate=evaluate,\n",
    "            no_cache=no_cache,\n",
    "            multi_label=multi_label,\n",
    "            verbose=verbose,\n",
    "            silent=silent,\n",
    "        )\n",
    "\n",
    "    def compute_metrics(\n",
    "        self, preds, model_outputs, labels, eval_examples, multi_label=True, **kwargs\n",
    "    ):\n",
    "        return super().compute_metrics(\n",
    "            preds,\n",
    "            model_outputs,\n",
    "            labels,\n",
    "            eval_examples,\n",
    "            multi_label=multi_label,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def predict(self, to_predict, multi_label=True):\n",
    "        return super().predict(to_predict, multi_label=multi_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fbd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfdefea",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Set the following settings to conduct experiments in the report:\n",
    "\n",
    "| Experiment Number | MAX_TOKEN_COUNT | WITH_IMPLICIT_SKILLS | EXPERIMENT | MODEL_COMPLEXITY\n",
    "| --- | --- | --- | --- | --- | \n",
    "| 1 | 512 | True | sample20000 | advanced2 |\n",
    "| 2 | 256 | True | newsample20000 | advanced2 |\n",
    "| 3 | 256 | True | newsample20000 | advanced |\n",
    "| 4 | 256 | True | newsample20000 | basic |\n",
    "| 5 | 256 | False | newsample20000 | advanced2 |\n",
    "| 6 | 256 | True | newsample20000 | advanced2Multilingual |\n",
    "| 7 | 256 | - | bhola | advanced2Multilingual |\n",
    "| 8 | 256 | - | bhola | advanced2 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936fa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "MAX_TOKEN_COUNT = 256 # Change this\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "WARMUP_PROPORTION = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "LEARNING_RATE = 1e-4\n",
    "MANUAL_SEED = 42\n",
    "\n",
    "TRAIN_MODEL = True # Change this \n",
    "WITH_IMPLICIT_SKILLS = True # Change this \n",
    "\n",
    "if WITH_IMPLICIT_SKILLS:\n",
    "    COL_SKILLS = \"totalskills\"\n",
    "    IMPLICITNESS = \"InclImplicit\"\n",
    "else:\n",
    "    COL_SKILLS = \"skills\"\n",
    "    IMPLICITNESS = \"ExclImplicit\"\n",
    "    \n",
    "if EPOCHS != 5:\n",
    "    N_EPOCHS = '_Epochs' + str(EPOCHS)\n",
    "else:\n",
    "    N_EPOCHS = ''\n",
    "\n",
    "# FILES\n",
    "s3 = boto3.client('s3')\n",
    "BUCKET = 'NAME_OF_BUCKET' # Change this\n",
    "PATH_TO_FILE = 'PATH_TO_FILE' # Change this\n",
    "EXPERIMENT = 'bhola' # Change this \n",
    "\n",
    "MODEL_COMPLEXITY = 'advanced2' # Change this \n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    FILE_TO_READ_TRAIN = PATH_TO_FILE + 'bhola_dataset.train.pkl'\n",
    "    FILE_TO_READ_VALID = PATH_TO_FILE + 'bhola_dataset.valid.pkl'\n",
    "    FILE_TO_READ_TEST = PATH_TO_FILE + 'bhola_dataset.test.pkl'\n",
    "    IMPLICITNESS = ''\n",
    "    if MODEL_COMPLEXITY == 'advanced2Multilingual':\n",
    "        MODEL_TYPE = \"bert_xmlc\"\n",
    "        MODEL_NAME = \"bert-base-multilingual-uncased\"\n",
    "    elif MODEL_COMPLEXITY == 'advanced2':\n",
    "        MODEL_TYPE = \"bert_xmlc\"\n",
    "        MODEL_NAME = \"bert-base-uncased\"\n",
    "    else:\n",
    "        MODEL_TYPE = \"bert\"\n",
    "        MODEL_NAME = \"bert-base-uncased\"\n",
    "else:\n",
    "    FILE_TO_READ_TRAIN = PATH_TO_FILE + 'RobBERT_' + EXPERIMENT + '_train.csv'\n",
    "    FILE_TO_READ_VALID = PATH_TO_FILE + 'RobBERT_' + EXPERIMENT + '_valid.csv'\n",
    "    FILE_TO_READ_TEST = PATH_TO_FILE + 'RobBERT_' + EXPERIMENT + '_test.csv'\n",
    "    if MODEL_COMPLEXITY == 'advanced2Multilingual':\n",
    "        MODEL_TYPE = \"bert_xmlc\"\n",
    "        MODEL_NAME = \"bert-base-multilingual-uncased\"\n",
    "    elif MODEL_COMPLEXITY == 'advanced2':\n",
    "        MODEL_TYPE = \"roberta_xmlc\"\n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    elif MODEL_COMPLEXITY == 'advanced':\n",
    "        MODEL_TYPE = \"roberta_xmlc1\"\n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    elif MODEL_COMPLEXITY == 'basic':\n",
    "        MODEL_TYPE = \"roberta_xmlc_basic\"\n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    else:\n",
    "        MODEL_TYPE = \"roberta\" \n",
    "        MODEL_NAME = \"pdelobelle/robbert-v2-dutch-base\"\n",
    "    \n",
    "BEST_MODEL_DIR = 'outputs/model_' + EXPERIMENT + MODEL_COMPLEXITY + IMPLICITNESS + N_EPOCHS\n",
    "OUTPUT_RESULTS_OVERVIEW = EXPERIMENT + MODEL_COMPLEXITY + IMPLICITNESS + N_EPOCHS + '_results_overview.tsv'\n",
    "OUTPUT_RESULTS = EXPERIMENT + MODEL_COMPLEXITY + IMPLICITNESS + N_EPOCHS + '_results.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9f80c8",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "### Import the data from the s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT == 'bhola':\n",
    "    # Training dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TRAIN)\n",
    "    train_df = pickle.loads(obj['Body'].read())\n",
    "\n",
    "    # Validation dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_VALID)\n",
    "    valid_df = pickle.loads(obj['Body'].read())\n",
    "\n",
    "    # Test dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TEST)\n",
    "    test_df = pickle.loads(obj['Body'].read())\n",
    "    \n",
    "    print(len(train_df), len(valid_df), len(test_df))\n",
    "else: \n",
    "    # Training dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TRAIN)\n",
    "    train_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "    # Validation dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_VALID)\n",
    "    valid_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "    # Test dataset\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=FILE_TO_READ_TEST)\n",
    "    test_df = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "    print(train_df.shape, valid_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8925d46a",
   "metadata": {},
   "source": [
    "### Get complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d24c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPERIMENT != 'bhola':\n",
    "    dataset_df = pd.concat([train_df, valid_df, test_df], ignore_index = True)\n",
    "    print(dataset_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0494fc",
   "metadata": {},
   "source": [
    "### Preprocess the skills and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588225ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SKILLS ##### \n",
    "def clean_skills(skills):\n",
    "    skills = skills[1:-1]\n",
    "    skills = list(skills.split(\", \"))\n",
    "    return [skill[1:-1] for skill in skills]\n",
    "\n",
    "def get_skills(dataset):\n",
    "    skills_set = set()\n",
    "\n",
    "    for skills in dataset[COL_SKILLS]:\n",
    "        skills = clean_skills(skills)\n",
    "        skills_set.update(skills)\n",
    "        \n",
    "    return skills_set\n",
    "\n",
    "def skills_set_to_dict(skills_set):\n",
    "    skills_dict = {}\n",
    "    \n",
    "    for skill in list(skills_set):\n",
    "        skills_dict[skill] = 0\n",
    "        \n",
    "    return skills_dict\n",
    "\n",
    "def get_skills_dict(dataset): \n",
    "    skills_set = get_skills(dataset)\n",
    "    skills_dict = skills_set_to_dict(skills_set)\n",
    "    return skills_dict\n",
    "\n",
    "##### VACANCIES ##### \n",
    "def process_dataset_to_columns(df, skills_dict):\n",
    "    new_df_list = []\n",
    "    for i in range(len(df)):\n",
    "        # Get text\n",
    "        text = df.iloc[i][\"job_description\"]\n",
    "\n",
    "        # Get labels\n",
    "        label_skills_dict = skills_dict.copy()\n",
    "        skills = clean_skills(df.iloc[i][COL_SKILLS])\n",
    "\n",
    "        for skill in skills:\n",
    "            if skill in skills_dict.keys():\n",
    "                label_skills_dict[skill] = 1\n",
    "        labels = list(label_skills_dict.values())\n",
    "        new_df_list.append([text, labels])\n",
    "        \n",
    "    new_df = pd.DataFrame(new_df_list, columns=[\"text\", \"labels\"])\n",
    "    \n",
    "    return new_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa23eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SkillsExtractionDataset(total_df, train_df, val_df):\n",
    "    ''' Collects all input information for the BERT model. '''\n",
    "    # Get information about skills\n",
    "    skills_dict = get_skills_dict(total_df)\n",
    "    \n",
    "    ## Check if empty is in skills_dict, delete if necessary\n",
    "    if '' in skills_dict.keys():\n",
    "        skills_dict.pop('')\n",
    "        \n",
    "    num_of_labels = len(skills_dict.keys())\n",
    "    \n",
    "    # Get columns of train set\n",
    "    start_time = time.time()\n",
    "    print(f\"Start with creating the training dataset at {time.ctime()}.\")\n",
    "    train_col_df = process_dataset_to_columns(train_df, skills_dict)\n",
    "    print(f\"Creating the training dataset cost {(time.time() - start_time)/60} minutes.\")\n",
    "    \n",
    "    # Get columns of validation set\n",
    "    start_time = time.time()\n",
    "    print(f\"Start with creating the validation dataset at {time.ctime()}.\")\n",
    "    val_col_df = process_dataset_to_columns(val_df, skills_dict)\n",
    "    print(f\"Creating the validation dataset cost {(time.time() - start_time)/60} minutes.\")\n",
    "    \n",
    "    return dict(\n",
    "        num_of_labels= num_of_labels,\n",
    "        skills_dict = skills_dict,\n",
    "        train_col_df = train_col_df,\n",
    "        val_col_df = val_col_df,\n",
    "    )\n",
    "\n",
    "def data_process_bhola(dataset):\n",
    "    ''' If the experiment is with the bhola et al dataset, use this function to process the dataset. '''\n",
    "    # Separate text from labels\n",
    "    job_descriptions = [dataset[i][0] for i in range(len(dataset))]\n",
    "    skill_labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "    \n",
    "    # Create dataframe\n",
    "    data = {\"text\": job_descriptions, \"labels\": skill_labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    train_col_df = data_process_bhola(train_df)\n",
    "    val_col_df = data_process_bhola(valid_df)\n",
    "    NUM_OF_LABELS = 2548\n",
    "else:\n",
    "    dataset_dict = SkillsExtractionDataset(dataset_df, train_df, valid_df)\n",
    "    print(dataset_dict.keys())\n",
    "    NUM_OF_LABELS = dataset_dict['num_of_labels']\n",
    "    train_col_df = dataset_dict['train_col_df']\n",
    "    val_col_df = dataset_dict['val_col_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19151174",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NUM_OF_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e03a3a",
   "metadata": {},
   "source": [
    "## Training the model \n",
    "\n",
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d5f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = MultiLabelClassificationArgs()\n",
    "model_args.train_custom_parameters_only = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.max_seq_length = MAX_TOKEN_COUNT\n",
    "model_args.fp16 = False\n",
    "model_args.num_train_epochs = EPOCHS\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.best_model_dir = BEST_MODEL_DIR\n",
    "model_args.eval_batch_size = BATCH_SIZE\n",
    "model_args.train_batch_size = BATCH_SIZE\n",
    "model_args.manual_seed = MANUAL_SEED\n",
    "model_args.warmup_ratio = WARMUP_PROPORTION \n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_model_every_epoch = False\n",
    "\n",
    "if MODEL_COMPLEXITY == 'advanced2Multilingual':\n",
    "    model_args.do_lower_case = True\n",
    "    \n",
    "if MODEL_COMPLEXITY == 'advanced2Multilingual' or MODEL_COMPLEXITY == 'advanced2':\n",
    "    model_args.custom_parameter_groups = [\n",
    "    {\n",
    "        \"params\": [\"classifier.weight\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\"classifier.bias\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\"classifier_1.weight\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\"classifier_1.bias\"],\n",
    "        \"lr\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "    }\n",
    "    ]\n",
    "else:\n",
    "    model_args.custom_parameter_groups = [\n",
    "        {\n",
    "            \"params\": [\"classifier.weight\"],\n",
    "            \"lr\": LEARNING_RATE,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\"classifier.bias\"],\n",
    "            \"lr\": LEARNING_RATE,\n",
    "            \"weight_decay\": WEIGHT_DECAY,\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2563a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa75e9",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0439ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    # Check whether a CUDA is available\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "\n",
    "    model = MultiLabelClassificationModel(\n",
    "        MODEL_TYPE,\n",
    "        MODEL_NAME,\n",
    "        num_labels=NUM_OF_LABELS,\n",
    "        use_cuda=cuda_available,\n",
    "        args=model_args\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3047927",
   "metadata": {},
   "source": [
    "### Training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a2a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    start_time_train = time.time()\n",
    "    print(\"Start of training:\", start_time_train)\n",
    "\n",
    "    # Train the model\n",
    "    model.train_model(train_df = train_col_df, eval_df = val_col_df)\n",
    "\n",
    "    print(\"Training took\", (time.time()-start_time_train)/60, \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ae62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    start_time_val = time.time()\n",
    "    print(\"Start of validation:\", start_time_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    result, model_outputs, wrong_predictions = model.eval_model(val_col_df)\n",
    "\n",
    "    print(\"Validation took\", (time.time()-start_time_val)/60, \"minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    print(result)\n",
    "    print(model_outputs)\n",
    "    print(len(wrong_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e004ff37",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e4e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model if model is not yet loaded\n",
    "if not TRAIN_MODEL:\n",
    "    model = MultiLabelClassificationModel(\n",
    "        MODEL_TYPE, \n",
    "        BEST_MODEL_DIR,\n",
    "        num_labels=NUM_OF_LABELS,\n",
    "        use_cuda=False,\n",
    "        args=model_args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bcb0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_df(i, test_df):\n",
    "    # Get info from test item\n",
    "    text = test_df.iloc[i][\"job_description\"]\n",
    "    skills = test_df.iloc[i][COL_SKILLS]\n",
    "    \n",
    "    # Get the predicted labels and predicted probabilities\n",
    "    pred_labels, pred_probs = model.predict([text])\n",
    "    \n",
    "    # Turn skills from text to labels to get the true_labels    \n",
    "    skills_dict = dataset_dict['skills_dict'].copy()\n",
    "\n",
    "    skills = clean_skills(skills)\n",
    "    for skill in skills:\n",
    "        if skill in skills_dict.keys():\n",
    "            skills_dict[skill] = 1\n",
    "\n",
    "    true_labels = [v for v in skills_dict.values()]\n",
    "\n",
    "    # Get the name of each skill\n",
    "    skill_list = [s for s in skills_dict.keys()]\n",
    "    \n",
    "    # Create DataFrame for this test item\n",
    "    data = {\"true labels\": true_labels, \"pred labels\": pred_labels[0], \"pred probs\": pred_probs[0], \"skill\": skill_list}\n",
    "    test_item_df = pd.DataFrame(data) \n",
    "    ranked_test_item_df = test_item_df.sort_values(\"pred probs\", ascending=False)\n",
    "    \n",
    "    return ranked_test_item_df\n",
    "\n",
    "def get_ranked_df_bhola(i, test_df):\n",
    "    # Process dataset\n",
    "    test_col_df = data_process_bhola(test_df)\n",
    "    \n",
    "    # Get info from test item\n",
    "    text = test_col_df.iloc[i][\"text\"]\n",
    "    true_labels = test_col_df.iloc[i][\"labels\"]\n",
    "    \n",
    "    # Get the predicted labels and predicted probabilities\n",
    "    pred_labels, pred_probs = model.predict([text])\n",
    "    \n",
    "    # Create DataFrame for this test item\n",
    "    data = {\"true labels\": true_labels, \"pred labels\": pred_labels[0], \"pred probs\": pred_probs[0]}\n",
    "    test_item_df = pd.DataFrame(data) \n",
    "    ranked_test_item_df = test_item_df.sort_values(\"pred probs\", ascending=False)\n",
    "    \n",
    "    return ranked_test_item_df\n",
    "\n",
    "# Test if it worked\n",
    "if EXPERIMENT == 'bhola':\n",
    "    ranked_test_item_df = get_ranked_df_bhola(0, test_df)\n",
    "else:\n",
    "    ranked_test_item_df = get_ranked_df(0, test_df)\n",
    "    \n",
    "print(ranked_test_item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retrieved_skills(M, ranked_df):\n",
    "    skills = ranked_df['skill'].head(M)\n",
    "    return skills.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_values(ranked_df):\n",
    "    M = [5, 10, 30, 50, 100]\n",
    "    epsilon = 1.0e-4 # (To avoid zero-division)\n",
    "    metric_dict = {}\n",
    "    \n",
    "    true_labels = ranked_df['true labels'].to_numpy()\n",
    "    pred_labels = ranked_df['pred labels'].to_numpy()\n",
    "    \n",
    "    # Get indices of true relevant skills\n",
    "    true_index = np.where(true_labels==1)[0]\n",
    "    # Get amount of relevant skills for this job description\n",
    "    true_index_len = len(true_index)\n",
    "    # Get indices of predicted relevant skills\n",
    "    pred_index = np.where(pred_labels==1)[0]\n",
    "    \n",
    "    # Calculate RR\n",
    "    rr = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] == 1:\n",
    "            rr = 1/float(i+1)\n",
    "            break       \n",
    "    metric_dict['rr'] = rr\n",
    "    \n",
    "    # Calculate Recall@M and nDCG@M and get the skills\n",
    "    skills_list = []\n",
    "    idcg = np.sum([1.0/np.log2(x+2) for x in range(true_index_len)]) # +2 instead of +1 since the ranking starts with 0\n",
    "    for m in M:     \n",
    "        # Calculate Recall@m\n",
    "        correct = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1:\n",
    "                correct+=1\n",
    "        metric_dict[\"recall@\" + str(m)] = correct/(true_index_len+epsilon) # Epsilon to avoid zero-division\n",
    "        \n",
    "        # Calculate nDCG@m\n",
    "        dcg = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1: # Check if the skill on this position is relevant (only true labels necessary since the first m skills will be extracted non-the-less their classification)\n",
    "                dcg = dcg + 1.0/np.log2(i+2) # +2 to avoid zero-division\n",
    "        metric_dict[\"ndcg@\" + str(m)] = dcg/idcg\n",
    "        \n",
    "        # Get skills for @m\n",
    "        skills = get_retrieved_skills(m, ranked_df)\n",
    "        skills_list.append(skills)\n",
    "        \n",
    "    return metric_dict, skills_list\n",
    "\n",
    "def get_metrics_values_bhola(ranked_df):\n",
    "    M = [5, 10, 30, 50, 100]\n",
    "    epsilon = 1.0e-4 # (To avoid zero-division)\n",
    "    metric_dict = {}\n",
    "    \n",
    "    true_labels = ranked_df['true labels'].to_numpy()\n",
    "    pred_labels = ranked_df['pred labels'].to_numpy()\n",
    "    \n",
    "    # Get indices of true relevant skills\n",
    "    true_index = np.where(true_labels==1)[0]\n",
    "    # Get amount of relevant skills for this job description\n",
    "    true_index_len = len(true_index)\n",
    "    # Get indices of predicted relevant skills\n",
    "    pred_index = np.where(pred_labels==1)[0]\n",
    "    \n",
    "    # Calculate RR\n",
    "    rr = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i] == 1:\n",
    "            rr = 1/float(i+1)\n",
    "            break       \n",
    "    metric_dict['rr'] = rr\n",
    "    \n",
    "    # Calculate Recall@M and nDCG@M and get the skills\n",
    "    skills_list = []\n",
    "    idcg = np.sum([1.0/np.log2(x+2) for x in range(true_index_len)]) # +2 instead of +1 since the ranking starts with 0\n",
    "    for m in M:     \n",
    "        # Calculate Recall@m\n",
    "        correct = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1:\n",
    "                correct+=1\n",
    "        metric_dict[\"recall@\" + str(m)] = correct/(true_index_len+epsilon) # Epsilon to avoid zero-division\n",
    "        \n",
    "        # Calculate nDCG@m\n",
    "        dcg = 0\n",
    "        for i in range(m):\n",
    "            if true_labels[i] == 1: # Check if the skill on this position is relevant (only true labels necessary since the first m skills will be extracted non-the-less their classification)\n",
    "                dcg = dcg + 1.0/np.log2(i+2) # +2 to avoid zero-division\n",
    "        metric_dict[\"ndcg@\" + str(m)] = dcg/idcg\n",
    "        \n",
    "    return metric_dict\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    metric_dict = get_metrics_values_bhola(ranked_test_item_df)\n",
    "    print(metric_dict)\n",
    "else:\n",
    "    metric_dict, skills_list = get_metrics_values(get_ranked_df(5, test_df))\n",
    "    print(metric_dict)\n",
    "    print(skills_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metric_overview(test_df):\n",
    "    # Initiate lists\n",
    "    rec5 = []\n",
    "    rec10 = []\n",
    "    rec30 = []\n",
    "    rec50 = []\n",
    "    rec100 = []\n",
    "\n",
    "    ndcg5 = []\n",
    "    ndcg10 = []\n",
    "    ndcg30 = []\n",
    "    ndcg50 = []\n",
    "    ndcg100 = []\n",
    "\n",
    "    rr = []\n",
    "    \n",
    "    skills_all_items = []\n",
    "\n",
    "    for i in range(len(test_df)):    \n",
    "        ranked_df = get_ranked_df(i, test_df)\n",
    "        metric_dict, skills_list = get_metrics_values(ranked_df)\n",
    "\n",
    "        rec5.append(metric_dict[\"recall@5\"])\n",
    "        rec10.append(metric_dict[\"recall@10\"])\n",
    "        rec30.append(metric_dict[\"recall@30\"])\n",
    "        rec50.append(metric_dict[\"recall@50\"])\n",
    "        rec100.append(metric_dict[\"recall@100\"])\n",
    "\n",
    "        ndcg5.append(metric_dict[\"ndcg@5\"])\n",
    "        ndcg10.append(metric_dict[\"ndcg@10\"])\n",
    "        ndcg30.append(metric_dict[\"ndcg@30\"])\n",
    "        ndcg50.append(metric_dict[\"ndcg@50\"])\n",
    "        ndcg100.append(metric_dict[\"ndcg@100\"])\n",
    "\n",
    "        rr.append(metric_dict['rr'])\n",
    "        \n",
    "        skills_all_items.append(skills_list)\n",
    "    \n",
    "    return [rec5, rec10, rec30, rec50, rec100, ndcg5, ndcg10, ndcg30, ndcg50, ndcg100, rr], skills_all_items\n",
    "\n",
    "def get_metric_overview_bhola(test_df):\n",
    "    # Initiate lists\n",
    "    rec5 = []\n",
    "    rec10 = []\n",
    "    rec30 = []\n",
    "    rec50 = []\n",
    "    rec100 = []\n",
    "\n",
    "    ndcg5 = []\n",
    "    ndcg10 = []\n",
    "    ndcg30 = []\n",
    "    ndcg50 = []\n",
    "    ndcg100 = []\n",
    "    \n",
    "    rr = []\n",
    "\n",
    "    for i in range(len(test_df)):    \n",
    "        ranked_df = get_ranked_df_bhola(i, test_df)\n",
    "        metric_dict = get_metrics_values_bhola(ranked_df)\n",
    "\n",
    "        rec5.append(metric_dict[\"recall@5\"])\n",
    "        rec10.append(metric_dict[\"recall@10\"])\n",
    "        rec30.append(metric_dict[\"recall@30\"])\n",
    "        rec50.append(metric_dict[\"recall@50\"])\n",
    "        rec100.append(metric_dict[\"recall@100\"])\n",
    "\n",
    "        ndcg5.append(metric_dict[\"ndcg@5\"])\n",
    "        ndcg10.append(metric_dict[\"ndcg@10\"])\n",
    "        ndcg30.append(metric_dict[\"ndcg@30\"])\n",
    "        ndcg50.append(metric_dict[\"ndcg@50\"])\n",
    "        ndcg100.append(metric_dict[\"ndcg@100\"])\n",
    "\n",
    "        rr.append(metric_dict['rr'])\n",
    "    \n",
    "    return [rec5, rec10, rec30, rec50, rec100, ndcg5, ndcg10, ndcg30, ndcg50, ndcg100, rr]\n",
    "\n",
    "if EXPERIMENT == 'bhola':\n",
    "    metrics_overview = get_metric_overview_bhola(test_df)\n",
    "else:\n",
    "    metrics_overview, skills_all_items = get_metric_overview(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f075f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names_M = ['recall5', 'recall10', 'recall30', 'recall50', 'recall100', \\\n",
    "                 'ndcg5', 'ndcg10', 'ndcg30', 'ndcg50', 'ndcg100', 'rr']\n",
    "\n",
    "metric_overview_dict = {}\n",
    "metric_and_skill_per_item = {}\n",
    "\n",
    "# Do not take into account vacancies without any explicit skills\n",
    "ignore_indices = []\n",
    "\n",
    "ndcg_5 = metrics_overview[5]\n",
    "for i in range(len(ndcg_5)):\n",
    "    if np.isnan(ndcg_5[i]):\n",
    "        ignore_indices.append(i)\n",
    "        \n",
    "print(f\"The values of {len(ignore_indices)} vacancies will not be taken into account\")\n",
    "\n",
    "for i in range(len(metric_names_M)):\n",
    "    metric = metric_names_M[i]\n",
    "    values_all = metrics_overview[i]\n",
    "    \n",
    "    values = []\n",
    "    for i in range(len(values_all)):\n",
    "        if i not in ignore_indices:\n",
    "            values.append(values_all[i])\n",
    "    \n",
    "    metric_overview_dict[metric] = [np.mean(values), np.median(values), np.min(values), np.max(values)]\n",
    "    metric_and_skill_per_item[metric] = values_all\n",
    "    \n",
    "print(f\"The mean, median, min and max values per metric@m are: \\n\", metric_overview_dict)\n",
    "# Create a dataframe to easily download the overview of the results\n",
    "df_results_overview = pd.DataFrame(metric_overview_dict)\n",
    "# Download as TSV\n",
    "df_results_overview.to_csv(OUTPUT_RESULTS_OVERVIEW, sep='\\t',index=False)\n",
    "\n",
    "# Create a dataframe to easily download the results\n",
    "df_results = pd.DataFrame(metric_and_skill_per_item)\n",
    "if EXPERIMENT != 'bhola':\n",
    "    # Add skills\n",
    "    df_results[\"retrievedskills\"] = skills_all_items\n",
    "    \n",
    "# Download as TSV\n",
    "df_results.to_csv(OUTPUT_RESULTS, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
